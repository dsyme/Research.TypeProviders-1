\documentclass[10pt,preprint,blind,clearpagebib]{sigplanconf}

\usepackage{listings}
\usepackage{enumitem}
\usepackage[hyphens]{url}
\usepackage[svgnames]{xcolor}
\definecolor{lcl}{RGB}{140,0,100}
\usepackage[colorlinks=true,breaklinks,draft=false]{hyperref}
\hypersetup{urlcolor=lcl,linkcolor=lcl,citecolor=lcl}
\newcommand{\doi}[1]{doi:~\href{http://dx.doi.org/#1}{\Hurl{#1}}}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage[fleqn]{amsmath}
\usepackage{graphics} 
\usepackage{stmaryrd}
\usepackage{amsthm}
\usepackage{ftnright}
\usepackage[T1]{fontenc}
\usepackage{semantic}
\usepackage{enumitem}
\usepackage[hang,flushmargin]{footmisc} 
\usepackage[notquote]{hanging}
\usepackage{flushend}

% =================================================================================================

% TODO: Discuss 'stability' of the inference (minor change in schema does not cause dramatic cahnges)
% TODO: Say that variant is a last-resort thing
% TODO: Practical evaluation (lots of downloads, lots of Github - how often people customize samples?)
% TODO: Explain why we need option type (because T + null is a variant)
% TODO: In the PLDI version, we delete all the unnecessary runtime conversions
% but we should say that those happen for practical reasons (e.g. float -> int, or anyhing to string)

\urlstyle{sf}

\makeatletter
\renewcommand{\@makefntext}[1]{%
  \parindent 1em%
  \raggedright
  \begin{hangparas}{0.8em}{1}
  \noindent {$^{\@thefnmark}$~#1}
  \end{hangparas}
}
\makeatother

\newcommand{\langl}{\begin{picture}(4.5,7)
\put(1.1,2.5){\rotatebox{60}{\line(1,0){5.5}}}
\put(1.1,2.5){\rotatebox{300}{\line(1,0){5.5}}}
\end{picture}}
\newcommand{\rangl}{\begin{picture}(4.5,7)
\put(.9,2.5){\rotatebox{120}{\line(1,0){5.5}}}
\put(.9,2.5){\rotatebox{240}{\line(1,0){5.5}}}
\end{picture}}

\newcommand{\lang}{\begin{picture}(5,7)
\put(1.1,2.5){\rotatebox{45}{\line(1,0){6.0}}}
\put(1.1,2.5){\rotatebox{315}{\line(1,0){6.0}}}
\end{picture}}
\newcommand{\rang}{\begin{picture}(5,7)
\put(.1,2.5){\rotatebox{135}{\line(1,0){6.0}}}
\put(.1,2.5){\rotatebox{225}{\line(1,0){6.0}}}
\end{picture}} 

\newcommand{\llangl}{\langl\hspace{-0.35em}\langl}
\newcommand{\rrangl}{\rangl\hspace{-0.35em}\rangl}

\definecolor{cmtclr}{rgb}{0.0,0.6,0.0}
\definecolor{numclr}{rgb}{0.0,0.4,0.0}
\definecolor{kvdclr}{rgb}{0.0,0.0,0.6}
\definecolor{strclr}{rgb}{0.5,0.1,0.0}
\definecolor{prepclr}{rgb}{0.0,0.0,0.0}

\newcommand{\kvd}[1]{\textnormal{\textcolor{kvdclr}{\sffamily #1}}}
\newcommand{\num}[1]{\textnormal{\textcolor{numclr}{\sffamily #1}}}
\newcommand{\str}[1]{\textnormal{\textcolor{strclr}{\sffamily "#1"}}}
\newcommand{\strf}[1]{\textnormal{\textcolor{strclr}{\sffamily #1}}}
\newcommand{\ident}[1]{\textnormal{\sffamily #1}}
\newcommand{\lident}[1]{\textnormal{\sffamily\`{}\hspace{-0.25em}\`{}\hspace{-0.1em}#1\`{}\hspace{-0.25em}\`{}}}
\newcommand{\cmt}[1]{\textit{\sffamily\textcolor{cmtclr}{#1}}}

\newcommand{\lsep}[0]{\;\; | \;\;}
\newcommand{\narrow}[1]{\hspace{-0.7em} #1 \hspace{-0.7em}}

\newcommand{\tsep}[0]{\; \triangledown \;}
\newcommand{\tytag}{\ident{tag}}
\newcommand{\dropopt}[1]{\lfloor#1\rfloor}
\newcommand{\addopt}[1]{\lceil#1\rceil}
\newcommand{\tytagof}{\ident{tagof}}
\newcommand{\nameoftag}{\ident{nameof}}

\newcommand{\reduce}{\rightsquigarrow}

\newcommand{\sem}[1]{\llbracket #1 \rrbracket}
\newcommand{\semalt}[1]{\llangl #1 \rrangl}

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}

% =================================================================================================

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}
\conferenceinfo{CONF 'yy}{Month d--d, 20yy, City, ST, Country} 
\copyrightyear{20yy} 
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm} 
%\doi{nnnnnnn.nnnnnnn}

%\titlebanner{Unpublished draft, March 2015}        % These are ignored unless
%\preprintfooter{short description of paper}        % 'preprint' option specified.

\title{Types from data: \textnormal{Making structured data first-class citizens in F\#}}
%\subtitle{Subtitle Text, if any}

\authorinfo{Tomas Petricek}
           {University of Cambridge}
           {tomas@tomasp.net}
\authorinfo{Gustavo Guerra}
           {Microsoft Corporation, London}
           {gustavo@codebeside.org}
\authorinfo{Don Syme}
           {Microsoft Research, Cambridge}
           {dsyme@microsoft.com}
\maketitle

% =================================================================================================

\begin{abstract}
Most modern applications interact with external services and access data in structured formats such 
as XML, JSON and CSV. Static type systems do not understand such formats, often making data access
more cumbersome. Should we give up and leave the messy world of external data to dynamic typing 
and runtime checks? Of course, not!

In this paper, we integrate external structured data into the F\# type system. As most real-world data
does not come with an explicit schema, we develop a shape inference algorithm that infers a shape from 
representative sample documents and integrate it into the F\# type system using type providers.

Our library significantly reduces the amount of data access code and it provides additional 
safety guarantees when contrasted with the widely used weakly typed techniques.
\end{abstract}

\category{D.3.3}{Programming Languages}{Language Constructs and Features }
\keywords F\#, Type Providers, Inference, JSON, XML



% =================================================================================================
%
%   ###                                                                       
%    #  #    # ##### #####   ####  #####  #    #  ####  ##### #  ####  #    # 
%    #  ##   #   #   #    # #    # #    # #    # #    #   #   # #    # ##   # 
%    #  # #  #   #   #    # #    # #    # #    # #        #   # #    # # #  # 
%    #  #  # #   #   #####  #    # #    # #    # #        #   # #    # #  # # 
%    #  #   ##   #   #   #  #    # #    # #    # #    #   #   # #    # #   ## 
%   ### #    #   #   #    #  ####  #####   ####   ####    #   #  ####  #    # 
%
% =================================================================================================

\section{Introduction}
\label{sec:introduction}

Social network clients, applications for finding tomorrow's weather or searching train schedules
all communicate with external services. Increasing number of such services provide REST-based 
end-points that return data as CSV, XML or JSON. Despite many schematization efforts, most 
services do not come with an explicit schema. At best, the documentation provides sample responses 
for typical requests.

For example, \url{http://openweathermap.org/current} provides an end-point to get the current weather.
The documentation shows one sample to illustrate the typical response. Using 
standard JSON and web libraries, we might write:

\noindent
\begin{equation*}
\begin{array}{l}
 \kvd{let}~\ident{doc}=\ident{Http.Request}(\str{http://api.owm.org/?q=NYC}) \\
 \kvd{match}~\ident{JsonValue.Parse}(\ident{doc})~\kvd{with} \\
 |~\ident{Record}(\ident{root})\rightarrow \\
 \quad \kvd{match}~\ident{Map.find}~\str{main}~\ident{root}~\kvd{with} \\
 \quad |~\ident{Record}(\ident{main})\rightarrow \\
 \quad \quad \kvd{match}~\ident{Map.find}~\str{temp}~\ident{main}~\kvd{with} \\
 \quad \quad |~\ident{Number}(\ident{num})\rightarrow \ident{printfn}~\str{Lovely \%f!}~\ident{num} \\
 \quad \quad |~\_\rightarrow \ident{failwith}~\str{Incorrect format} \\
 \quad |~\_\rightarrow \ident{failwith}~\str{Incorrect format} \\
 |~\_\rightarrow \ident{failwith}~\str{Incorrect format} 
\end{array}
\end{equation*}
%
The code assumes that the response has a particular shape described in the documentation. The
root node must be a record with a \str{main} field, which has to be another record containing
a numerical \str{temp} field. When the shape is different, the code simply fails with an exception. 
While not immediately unsound, the code is manifestly prone to errors if strings are misspelled 
or incorrect shape assumed.

Using the JSON type provider from F\# Data, we can write code with exactly the 
same functionality in two lines:
%
\vspace{-0.1em}
\begin{equation*}
\begin{array}{l}
 \kvd{type}~\ident{W} = \ident{JsonProvider}\langl\str{http://api.owm.org/?q=NYC}\rangl \\[0.1em]
 \ident{printfn}~\str{Lovely \%f!}~(\ident{W.GetSample().Main.Temp})
\end{array}
\end{equation*}
%
$\ident{JsonProvider}\langl\str{...}\rangl$ invokes a type provider at 
compile-time with the URL as a sample. The type provider infers the structure of the response
and provides a type with a \ident{GetSample} method that returns a parsed JSON with nested
properties \ident{Main.Temp}, returning the temperature as a number.

In short, \emph{the types come from the sample data}. In our experience, this technique is 
immensely practical and surprisingly effective in achieving sound information interchange 
in heterogeneous systems. This paper presents our approach:

\begin{itemize}
\item We present F\# Data type providers for XML, CSV and JSON (\S\ref{sec:providers}) 
  and practical aspects of their implementation that contributed to their industrial 
  adoption (\S\ref{sec:impl}). 

\item We describe a predictable shape inference algorithm for structured data formats, 
  based on a \emph{preferred shape} relation, that underlies the type providers 
  (\S\ref{sec:inference}).

\item We give a formal model (\S\ref{sec:formal}) and use it to prove
  \emph{relativized type safety} for the type providers (\S\ref{sec:safety}).
  This adapts the ML-style type safety for the context of the web.
\end{itemize}

\vspace{-0.1em}
\noindent
The supplementary screencast illustrates the practical developer experience using 
  F\# Data with JSON, XML and CSV.


% =================================================================================================
%
%   #######                                                                                  
%      #    #   # #####  ######    #####  #####   ####  #    # # #####  ###### #####   ####  
%      #     # #  #    # #         #    # #    # #    # #    # # #    # #      #    # #      
%      #      #   #    # #####     #    # #    # #    # #    # # #    # #####  #    #  ####  
%      #      #   #####  #         #####  #####  #    # #    # # #    # #      #####       # 
%      #      #   #      #         #      #   #  #    #  #  #  # #    # #      #   #  #    # 
%      #      #   #      ######    #      #    #  ####    ##   # #####  ###### #    #  ####  
%
% =================================================================================================

\section{Type providers for structured data}
\label{sec:providers}

We start with an informal overview that shows how F\# Data type providers simplify working with 
JSON and XML. We introduce the necessary aspects of F\# type providers along the way. The examples 
in this section illustrate the key design principles of the shape inference algorithm:

\begin{itemize}
\item The mechanism is predictable. The user directly works with the provided types and should 
  understand why a specific type was produced from a given sample.\footnote{In particular, we do 
  not use probabilistic methods where adding an additional sample could completely change the 
  shape of the type.}

\item The type providers prefer F\# objects with properties. This is to allow extensible 
  (open-world) data formats (\S\ref{sec:providers-xml}). It also interacts well with developer tooling
  as most F\# editors provide auto-completion on ``.'' and so objects are easier to use than 
  types that require pattern matching.

\item Finally, the mechanism handles practical concerns important in the real world. This includes 
  support for different numerical types, \kvd{null} values and missing data.
\end{itemize}

% --------------------------------------------------------------------------------------------------

\subsection{Working with JSON documents}
\label{sec:providers-json}

The JSON format is a popular data exchange format based on 
JavaScript data structures. The following is the definition of \ident{JsonValue} 
used earlier (\S\ref{sec:introduction}) to represent JSON data:
%
\begin{equation*}
\begin{array}{l}
 \kvd{type}~\ident{JsonValue} = \\[0.1em]
 \quad|~ \ident{Number}~\kvd{of}~\ident{float} ~~~~|~ \ident{Boolean}~\kvd{of}~\ident{bool} \\[0.1em]
 \quad|~ \ident{String}~\kvd{of}~\ident{string} ~~\qquad\, |~ \ident{Null} \\[0.1em]
 \quad|~ \ident{Record}~\kvd{of}~\ident{Map}\langl\ident{string}, \ident{JsonValue}\rangl \\[0.1em]
 \quad|~ \ident{Array}~\kvd{of}~\ident{JsonValue}[] \\[0.1em]
\end{array}
\end{equation*}
%
The earlier example used only a nested record containing a number. To demonstrate other 
aspects of the JSON type provider, we look at an example that also involves an array:
%
{\small{
\begin{verbatim}
  [ { "name":"Jan", "age":25 }, { "name":"Tomas" },
    { "name":"Alexander", "age":3.5 } ]
\end{verbatim}
}}
%
\noindent
The standard approach to print the names and ages would be to pattern match on the parsed 
\ident{JsonValue}, check that the top-level node is a \ident{Array} and iterate over the elements 
checking that each element is a \ident{Record} with certain properties. We would throw an exception 
for values of an incorrect shape. As before, the code would specify field names as strings, which 
is error prone and can not be statically checked.

Assuming \strf{people.json} is the above example and \ident{data} is a string containing
JSON of the same shape, we can write:
%
\begin{equation*}
\begin{array}{l}
 \kvd{type}~\ident{People}~=~\ident{JsonProvider}\langl\str{people.json}\rangl\hspace{1em} \\[0.6em]
 \kvd{for}~\ident{item}~\kvd{in}~\ident{People.Parse}(\ident{data})~\kvd{do}\\[0.1em]
 \quad\ident{printf}~\str{\%s }~\ident{item.Name}\\[0.1em]
 \quad\ident{Option.iter}~(\ident{printf}~\str{(\%f)})~\ident{item.Age}
\end{array}
\end{equation*}
%
In contrast to the earlier example, we now use a local file \strf{people.json} as a sample for 
the type inference, but then processes data from another source. The code achieves a similar 
simplicity as when using dynamically typed languages, but it is statically type-checked.

\paragraph{Type providers.}
The notation $\ident{JsonProvider}\langl\str{people.json}\rangl$ passes a \emph{static parameter} 
to the type provider. Static parameters are resolved at compile-time and have to be constant. 
The provider analyzes the sample and generates a type  \ident{People}. Most F\# editors also 
execute the type provider in the background at development-time and use the provided types 
in auto-completion and background type-checking.

The \ident{JsonProvider} uses a shape inference algorithm and provides
the following F\# types for the sample:
%
\begin{equation*}
\begin{array}{l}
 \kvd{type}~\ident{Entity}~=  \\
 \quad \kvd{member}~\ident{Name}~:~\ident{string} \\
 \quad \kvd{member}~\ident{Age}~:~\ident{option}\langl \ident{float}\rangl \\[0.5em]
 \kvd{type}~\ident{People}~=  \\
 \quad \kvd{member}~\ident{GetSample}~:~\ident{unit}~\rightarrow~\ident{Entity}[] \\
 \quad \kvd{member}~\ident{Parse}~:~\ident{string}~\rightarrow~\ident{Entity}[] \\
\end{array}
\end{equation*}
%
The type \ident{Entity} represents the person. The field \ident{Name} is available for all
sample values and is inferred as \ident{string}. The field \ident{Age} is marked as optional,
because the value is missing in one sample. The two age values are an integer $25$ and a 
float $3.5$ and so the common inferred type is \ident{float}.

The type \ident{People} has two methods for reading data. \ident{GetSample} parses the
sample used for the inference and \ident{Parse} parses a JSON string. This lets us read
data at runtime, provided that it has the same shape as the static sample.

\paragraph{Error handling.}
In addition to the structure of the types, the type provider also specifies what code should be 
executed at run-time in place of \ident{item.Name} and other operations. The runtime behaviour is 
the same as in the earlier hand-written sample (\S\ref{sec:introduction}) -- a member access 
throws an exception if data does not have the expected shape.

Informally, the safety property (\S\ref{sec:safety}) states that if the inputs are compatible
with one of the static samples (i.e.~the samples are representative), then no exceptions will 
occur. In other words, we cannot avoid all failures, but we can prevent some. Moreover, if 
\url{http://openweathermap.org} changes the shape of the response, the code in \S\ref{sec:introduction}
will not re-compile and the developer knows that the code needs to be changed. 

\paragraph{The role of objects with properties.}
The sample code is easy to write thanks to the fact that most F\# editors provide auto-completion
when ``.'' is typed (see the supplementary screencast). The developer does not need to look at the 
sample JSON file to see what fields are available. To support this scenario, our type providers 
map the inferred shapes to F\# objects with (possibly optional) properties.

This is demonstrated by the fact that \ident{Age} becomes an optional member.
An alternative is to provide two different record types (one with \ident{Name} and other with 
\ident{Name} and \ident{Age}), but this would complicate the processing code.
It is worth noting that languages with stronger tooling around pattern matching
such as Idris \cite{idris-tools} might have different preferences.

% -------------------------------------------------------------------------------------------------

\subsection{Processing XML documents}
\label{sec:providers-xml}

XML documents are formed by nested elements with attributes. We can view elements as records with 
a field for each attribute and an additional special field for the nested contents (which is a 
collection of elements).

Consider a simple extensible document format where a root element {\ttfamily\small <doc>} can 
contain a number of document elements, one of which is {\ttfamily\small <heading>} representing 
headings:
%
{\small{
\begin{verbatim}
  <doc>
    <heading>Working with JSON</heading>
    <p>Type providers make this easy.</p>
    <heading>Working with XML</heading>
    <p>Processing XML is as easy as JSON.</p>
    <image source="xml.png" />
  </doc>
\end{verbatim}
}}
%
\noindent
The F\# Data library has been designed primarily to simplify reading of data. For example,
say we want to print all headings in the document. The sample shows a part of the document structure 
(in particular the {\ttfamily\small <heading>} element), but it does not show all possible elements 
(say, {\ttfamily\small <table>}). Assuming the above document is \strf{sample.xml}, we can write:
%
\noindent
\begin{equation*}
\begin{array}{l}
 \kvd{type}~\ident{Document}~=~\ident{XmlProvider}\langl\str{sample.xml}\rangl\hspace{1em} \\[0.5em]
 \kvd{let}~\ident{root}~=~\ident{Document.Load}(\str{c:/pldi/another.xml})\\
 \kvd{for}~\ident{elem}~\kvd{in}~\ident{root.Doc}~\kvd{do}\\
 \quad\ident{Option.iter}~(\ident{printf}~\str{ - \%s})~\ident{elem.Heading}\\
\end{array}
\end{equation*}
%
The example iterates over a collection of elements returned by \ident{root.Doc}. The type of \ident{elem} 
provides a typed access to elements known from the sample and so we can write \ident{elem.Heading}, 
which returns an optional string value.

\paragraph{Open world.}
By its nature, XML is extensible and the sample cannot include all possible nodes.\footnote{Even 
when the document structure is defined using XML Schema, documents may contain elements prefixed 
with other namespaces.} This is the important \emph{open world assumption} about external data. 
Actual input might be an element about which nothing is known.

For this reason, we do not infer a closed choice between heading, paragraph and image. In the 
subsequent formalization, we introduce a \emph{top shape} (\S\ref{sec:inference-types}) and extend 
it with labels capturing the statically known possibilities (\S\ref{sec:inference-vars}). The 
\emph{labelled top shape} is mapped to the following type:
%
\begin{equation*}
\begin{array}{l}
 \kvd{type}~\ident{Element}~=  \\[0.1em]
 \quad \kvd{member}~\ident{Heading}~:~\ident{option}\langl \ident{string} \rangl\\
 \quad \kvd{member}~\ident{Paragraph}~:~\ident{option}\langl \ident{string} \rangl\\
 \quad \kvd{member}~\ident{Image}~:~\ident{option}\langl \ident{Image} \rangl\\
\end{array}
\end{equation*}
%
This provides access to the elements known statically from the sample. However the type is 
deliberately `weak', because the user needs to explicitly handle the case when a value is not 
a statically known element. The above code uses \ident{Option.iter} to skip all unknown elements. 

The provided type is also consistent with our design principles, which prefers optional properties. 
The gain is that the provided types support both open-world data and developer tooling. It is also 
worth noting that our shape inference uses labelled top shapes only as the last resort 
(Theorem~\ref{thm:lub}, \S\ref{sec:impl-hetero}).

% -------------------------------------------------------------------------------------------------

\subsection{Summary}
\label{sec:providers-sum}
Throughout the introduction, we used data sets that demonstrate the typical problems that are frequent
in the real-world (\emph{missing data}, \emph{inconsistent encoding} of primitive values and 
\emph{heterogeneous shapes}). In our experience, these are the most common issues. The following 
JSON response with government debt information returned by the World Bank\footnote{Available at 
\url{http://data.worldbank.org}} demonstrates all three problems:
%
{\small{
\begin{verbatim}
  [ { "page": 1, "pages": 5 },
    [ { "indicator": "GC.DOD.TOTL.GD.ZS",
        "date": "2012", "value": null },
      { "indicator": "GC.DOD.TOTL.GD.ZS",
        "date": "2010", "value": "35.14229" } ] ]
\end{verbatim}
}}
%
\noindent
First of all, the top-level element is a collection containing two values of different kind.
The first is a record with meta-data about the current page and the second is an array with data. 
The actual F\# Data implementation supports a concept of heterogeneous collections (briefly outlined
in \S\ref{sec:impl-hetero}) and provides a type with properties \ident{Record} for the former and 
\ident{Array} for the latter. Second, the \ident{value} field is \kvd{null} for some records. Third, 
numbers can be represented in JSON as numeric literals (without quotes), but here, they are 
returned as string literals instead.\footnote{This is often used to avoid non-standard numerical 
types of JavaScript.}

In addition to type providers for JSON and XM, F\# Data also implements a type provider for CSV 
(\S\ref{sec:impl-parsing}). We treat CSV files as lists of records (with field for each column) 
and so CSV is handled directly by our inference algorithm.


% =================================================================================================
%
%     #####
%    #     # #    #   ##   #####  ######    # #    # ###### ###### #####  ###### #    #  ####  ######
%    #       #    #  #  #  #    # #         # ##   # #      #      #    # #      ##   # #    # #
%     #####  ###### #    # #    # #####     # # #  # #####  #####  #    # #####  # #  # #      #####
%          # #    # ###### #####  #         # #  # # #      #      #####  #      #  # # #      #
%    #     # #    # #    # #      #         # #   ## #      #      #   #  #      #   ## #    # #
%     #####  #    # #    # #      ######    # #    # #      ###### #    # ###### #    #  ####  ######
%
% =================================================================================================

\section{Shape inference for structured data}
\label{sec:inference}

The shape inference algorithm for structured data is based on a shape preference relation. When 
inferring the shape, it infers the most specific shapes of individual values (CSV rows, JSON or XML 
nodes) and recursively finds a common shape of all child nodes or all sample documents.

We first define the shape of structured data $\sigma$. We use the term \emph{shape} to distinguish 
shapes from programming language \emph{types} $\tau$ (type providers generate the latter from the former). 
Next, we define the preference relation on shapes $\sigma$ and describe the algorithm 
for finding a common shape. 

% --------------------------------------------------------------------------------------------------

\begin{figure}
\begin{center}
\includegraphics[scale=0.80,trim=5mm 5mm 5mm 5mm,clip]{images/hierarchy.pdf} % left bottom right top
\end{center}
\vspace{-0.5em}
\caption{Subtype relation between structural types}
\label{fig:subtyping-diagram}
\vspace{-0.5em}
\end{figure}

% -------------------------------------------------------------------------------------------------

\subsection{Inferred shapes}
\label{sec:inference-types}

We distinguish between \emph{non-nullable shapes} that always have a valid value (written as 
$\hat{\sigma}$) and \emph{nullable shapes} that encompass missing and \kvd{null} values 
(written as $\sigma$). We write $\nu$ for record names and record field names. In the rest of the
paper, we assume that record fields can be freely reordered:
%
\begin{equation*}
\begin{array}{rcl}
 \hat{\sigma} &\narrow{=}& \nu \; \{ \nu_1 : \sigma_1, \ldots, \nu_n : \sigma_n \} \\[0.1em]
                &\narrow{|}& \ident{float} \lsep \ident{int} \lsep \ident{bool} \lsep \ident{string} 
 \\[0.6em] 
       \sigma &\narrow{=}& ~\hat{\sigma}~ \lsep \kvd{nullable}\langl \hat{\sigma} \rangl \lsep [\sigma] \lsep \kvd{any} \lsep \kvd{null}  \lsep ~\bot~
\end{array}
\end{equation*}

\noindent
Non-nullable shapes include records (consisting of a name and fields with their shapes) and 
primitives. Names of records arising from XML are the names of the XML elements while
JSON records always use a single name $\bullet$.

We include two numerical primitives, \ident{int} for integers and \ident{float} for floating-point 
numbers. The two are related by the perference relation and we prefer \ident{int}.

Any non-nullable shape $\hat{\sigma}$ can be wrapped as $\kvd{nullable}\langl\hat{\sigma}\rangl$ to 
explicitly permit the \kvd{null} value. Type providers map \kvd{nullable} shapes to the F\# option
type. A collection $[\sigma]$ is also nullable and \kvd{null} values are treated as empty 
collections. The shape $\kvd{null}$ is inhabited by the $\kvd{null}$ value (using an overloaded 
notation) and $\bot$ is the bottom shape. The \kvd{any} shape is the top shape, but we revisit it 
later by adding labels for statically known alternative shapes (\S\ref{sec:inference-vars}) as 
discussed earlier (\S\ref{sec:providers-xml}).

% -------------------------------------------------------------------------------------------------

\subsection{Preferred shape relation}
\label{sec:inference-subtyping}

Figure~\ref{fig:subtyping-diagram} provides an intuition about the preference between 
shapes. The upper part shows non-nullable shapes (with records and primitives) and the lower part 
shows nullable shapes with \kvd{null}, collections and nullable shapes. In the diagram, we 
abbreviate $\kvd{nullable}\langl\sigma\rangl$ as $\sigma?$ and we omit links between the two parts;
a shape $\hat{\sigma}$ is preferred over $\kvd{nullable}\langl\hat{\sigma}\rangl$.

\begin{definition}
We write $\sigma_1 \sqsupseteq \sigma_2$ to denote that $\sigma_2$ is preferred over $\sigma_1$. 
The shape preference relation is defined as a transitive reflexive closure of the following rules:

\noindent
\begin{align}
  \label{eq:sub-prim}\tag{P1}
  \ident{float}\,&\sqsupseteq\,\ident{int}&\\[-0.2em]
  \label{eq:sub-null}\tag{P2}
  \sigma &\sqsupseteq \kvd{null}  &(\textnormal{iff}~\sigma \neq \hat{\sigma})  \\[-0.2em]
  \label{eq:sub-opt}\tag{P3}
  \kvd{nullable}\langl\hat{\sigma}\rangl &\sqsupseteq \hat{\sigma}  &(\textnormal{for all}~\hat{\sigma})\\[-0.2em]
  \label{eq:sub-opt-cov}\tag{P4}
  \kvd{nullable}\langl\hat{\sigma_1}\rangl &\sqsupseteq 
    \kvd{nullable}\langl\hat{\sigma_2}\rangl  &(\textnormal{if}~\hat{\sigma_1} \sqsupseteq \hat{\sigma_2})\\[-0.2em]
  \label{eq:sub-col}\tag{P5}
  [\sigma_1] &\sqsupseteq [\sigma_2]  &(\textnormal{if}~\sigma_1 \sqsupseteq \sigma_2) \\[-0.2em]
  \label{eq:sub-bot}\tag{P6}
  \sigma &\sqsupseteq \bot  &(\textnormal{for all}~\sigma)\\[-0.2em]
  \label{eq:sub-var-top}\tag{P7}
  \kvd{any}\langl \sigma_1, \ldots, \sigma_n\rangl &\sqsupseteq \sigma 
\end{align}
\vspace{-2em}

\noindent
\begin{align}
\label{eq:sub-record1}\tag{R1}
\begin{array}{l}
 \nu~\{ \nu_1\!:\!\sigma_1, .., \nu_n\!:\!\sigma_n \} \sqsupseteq \\
 \quad\nu~\{ \nu_1\!:\!\sigma_1', .., \nu_n\!:\!\sigma_n' \}
\end{array} \qquad ~~~~(\textnormal{if}~\sigma_i \sqsupseteq \sigma_i')
\end{align}
\vspace{-1.5em}
\begin{align}
\label{eq:sub-record2}\tag{R2}
\begin{array}{l}
 \nu~\{ \nu_1\!:\!\sigma_1, .., \nu_n\!:\!\sigma_n \} \sqsupseteq \\
 \quad\nu~\{ \nu_1\!:\!\sigma_1, .., .., \nu_m\!:\!\sigma_m \}
\end{array} \quad~~\, (\textnormal{when}~m \geq n)
\end{align}
\vspace{-1.5em}
\begin{align}
\label{eq:sub-record3}\tag{R3}
\begin{array}{l}
 \nu~\{ \nu_1\!:\!\sigma_1, .., \nu_n\!:\!\sigma_n, \nu_{n+1}\!:\!\kvd{null} \} \sqsupseteq \\
 \quad\nu~\{ \nu_1\!:\!\sigma_1, .., \nu_n\!:\!\sigma_n \}
\end{array}
\end{align}
\end{definition}

% --------------------------------------------------------------------------------------------------

\begin{figure*}[t]
\noindent
\begin{equation*}
\begin{array}{rclcl}
 \tytag &\narrow{=}& \ident{collection}  &\narrow{\lsep}& \ident{number} \\
        &\narrow{\lsep}& \ident{nullable} &\narrow{\lsep}& \ident{string}  \\
        &\narrow{\lsep}& \nu ~\lsep \ident{any} &\narrow{\lsep}& \ident{bool}
\end{array}
%
\quad\;\;\;
%
\begin{array}{rcl}
 \tytagof(\ident{string}) &\narrow{=}& \ident{string}\\
 \tytagof(\ident{bool}) &\narrow{=}& \ident{bool}\\
 \tytagof(\ident{int}) &\narrow{=}& \ident{number}\\
 \tytagof(\ident{float}) &\narrow{=}& \ident{number}\\
\end{array}
%
\;\;
%
\begin{array}{rcl}
 \tytagof(\kvd{any}\langl\sigma_1, \ldots, \sigma_n\rangl) &\narrow{=}& \ident{any}\\
 \tytagof(\nu\; \{ \nu_1 : \sigma_1, \; \ldots \; , \nu_n : \sigma_n \}) &\narrow{=}& \nu \\
 \tytagof(\kvd{nullable}\langl\hat{\sigma}\rangl) &\narrow{=}& \ident{nullable}\\
 \tytagof([\sigma]) &\narrow{=}& \ident{collection}\\
\end{array}
\end{equation*}

\vspace{-0.5em}
\begin{equation*}
\quad\qquad\qquad
\begin{array}{rcll}
 \addopt{\hat{\sigma}} &\narrow{=}& \kvd{nullable}\langl\hat{\sigma}\rangl &(\textnormal{non-nullable shapes})\\
 \addopt{\sigma} &\narrow{=}& \sigma &(\textnormal{otherwise})
\end{array}
\qquad\qquad
\begin{array}{rcll}
 \dropopt{\kvd{nullable}\langl\hat{\sigma}\rangl} &\narrow{=}& \hat{\sigma} &(\textnormal{nullable shape})\\
 \dropopt{\sigma} &\narrow{=}& \sigma &(\textnormal{otherwise})
\end{array}
\end{equation*}

\vspace{-0.5em}
\begin{equation*}
% option types
\inference[(nullable)\;]
  {\hat{\sigma_1} \tsep \sigma_2 \vdash \sigma}
  {\kvd{nullable}\langl\hat{\sigma_1}\rangl \tsep \sigma_2 \vdash \kvd{nullable}\langl\dropopt{\sigma}\rangl}
\qquad
\inference[(any)\;]
  { \tytagof(\sigma_1) \neq \tytagof(\sigma_2) & \tytagof(\sigma_1) \neq \ident{nullable} \neq \tytagof{\sigma_2}}
  { \sigma_1 \tsep \sigma_2 \vdash \kvd{any} }  
\end{equation*}
\vspace{-2em}

\begin{equation*}
\hspace{4em}
\inference[(record)\;]
  { (\nu_i = \nu'_j) \Leftrightarrow (i = j) \wedge (i \leq k)
      \qquad \forall i\in\{ 1 .. k \}.(\sigma_i \tsep \sigma'_i \vdash \sigma''_i) }
  { \begin{array}{l}
    \nu \; \{ \nu_1 \!:\! \sigma_1,  \; \ldots \;, \nu_k \!:\! \sigma_k, \; \ldots \;, \nu_n \!:\! \tau_n \} \tsep
    \nu \; \{ \nu'_1 \!:\! \sigma'_1, \; \ldots \;, \nu'_k \!:\! \sigma'_k, \; \ldots \;, \nu'_m \!:\! \tau'_m \} \vdash\\
    \nu \; \{ \nu_1 \!:\! \sigma''_1, \; \ldots \; , \nu_k \!:\! \sigma''_k, 
                            \nu_{k+1} \!:\! \addopt{\sigma_{k+1}}, \ldots, \nu_n \!:\! \addopt{\sigma_n},
                            \nu'_{k+1} \!:\! \addopt{\sigma'_{k+1}}, \ldots, \nu'_m \!:\! \addopt{\sigma'_m} \}
    \end{array} }
\end{equation*}
\vspace{-2em}

% all rules are symmetric and reflexive
\begin{equation*}
\hspace{2em}
\inference[(list)\;]
  {\sigma_1 \tsep \sigma_2 \vdash \sigma}
  {[\sigma_1] \tsep [\sigma_2] \vdash [\sigma]}
\quad
\inference[(sym)\;]
  {\sigma_1 \tsep \sigma_2 \vdash \sigma}
  {\sigma_2 \tsep \sigma_1 \vdash \sigma}
%
\quad
\begin{array}{l}
 \textnormal{\footnotesize{(refl)}}\;\; \sigma \tsep \sigma \vdash \sigma\\[0.6em]
 % bottom type
 \textnormal{\footnotesize{(bot)}}\;\; \bot \tsep \sigma \vdash \sigma
\end{array}
%
\quad
% null and primitives
\begin{array}{l}
 \textnormal{\footnotesize{(null)}}\;\; \sigma \tsep \kvd{null} \vdash \addopt{\sigma} \quad (\sigma \neq \bot)\\[0.6em]
 \textnormal{\footnotesize{(prim)}}\;\; \kvd{int} \tsep \kvd{float} \vdash \kvd{float}
\end{array}
\end{equation*}

\caption{Inference judgements that define the common preferred shape relation}
\label{fig:subtyping-cst}
\end{figure*}

% --------------------------------------------------------------------------------------------------


\noindent
Here is a summary of the key aspects of the definition:
\begin{itemize}
\item Numeric shape with smaller range is preferred (\ref{eq:sub-prim}) and we choose 32-bit 
\ident{int} over \ident{float} when possible.

\item The \kvd{null} shape is preferred over all nullable shapes (\ref{eq:sub-null}), i.e. 
  all shapes excluding non-nullable shapes $\hat{\sigma}$. Any non-nullable shape is preferred
  over its nullable version (\ref{eq:sub-opt}); nullable shapes and collections are 
  covariant (\ref{eq:sub-opt-cov}, \ref{eq:sub-col}).

\item There is a bottom shape (\ref{eq:sub-bot}) and \kvd{any} behaves as the top shape, because
  any shape $\sigma$ is preferred over \kvd{any} (\ref{eq:sub-var-top}). 

\item The record shapes are covariant (\ref{eq:sub-record1}) and preferred record can have 
  additional fields (\ref{eq:sub-record2}). The rule (\ref{eq:sub-record3}) implies that records 
  can omit fields, provided that \kvd{null} is a valid value for the 
  field (i.e. the field is optional).
\end{itemize}

\noindent
The rule that allows preferred shapes to have fewer fields (\ref{eq:sub-record3}) is particularly
important. This is important, because it allows us to prefer records over the \kvd{any} 
shape. Given $\{ \ident{name}\!:\!\ident{string} \}$ and $\{ \ident{name}\!:\!\ident{string}, \ident{age}\!:\!\ident{int} \}$,
we find a common shape $\{ \ident{name}\!:\!\ident{string}, \ident{age}\!:\!\ident{int}~\kvd{option} \}$.
This is a least upper bound and more usable than the top shape $\kvd{var}$.

Some of the aspects of our system (numeric types and handling of missing data) offer a range of
choices. For example, OCaml also has different numerical types, but would likely always handle 
\kvd{null} explicitly.

% -------------------------------------------------------------------------------------------------

\subsection{Common preferred shape relation}
\label{sec:inference-commonsuper}

Given two shapes, the \emph{common preferred shape} relation finds a least upper bound
(Theorem~\ref{thm:lub}). It prefers records, which is important for usability as discussed
earlier.

\begin{definition}
A \emph{common preferred shape} of shapes $\sigma_1$ and $\sigma_2$ is a shape $\sigma$, written 
$\sigma_1 \tsep \sigma_2 \vdash \sigma$, obtained according to the inference rules in 
Figure~\ref{fig:subtyping-cst}.
\end{definition}

\noindent
We define shape \emph{tags} to identify shapes that have a common preferred shape which is not the
top shape. When finding a common shape of two records (\emph{record}), we return a record that has 
the union of their fields. The shape of shared fields becomes the common preferred shape of their 
respective shapes; fields that are present in only one record are marked as nullable using 
the function $\addopt{-}$.

We can find a common shape of two different numbers (\emph{prim}); for two collections,
we combine their elements (\emph{list}). When one shape is nullable (\emph{nullable}), we find
the common non-nullable shape and wrap it in \kvd{nullable}; if one of the shapes is \kvd{null}, 
we make the other one nullable (\emph{null}). Finally, if the two shapes do not have matching tags 
(and they are not nullable), we have to infer the \kvd{any} shape as there is no better alternative. 
The remaining rules for reflexivity, symmetry and the bottom shape are standard.

\paragraph{Properties.}
The set of shapes does not have a \emph{unique} least upper bound, but it 
has a least upper bound with respect to an equivalence between mutually preferred shapes. 
The common preferred shape relation defines a function (Theorem~\ref{thm:func}) that finds a
least upper bound (Theorem~\ref{thm:lub}). 

The equivalence on shapes groups records by their non-nullable fields. Given 
$\sigma_1 = \ident{A}~\{ \ident{a}\!:\!\ident{int}, \ident{b}\!:\!\kvd{nullable}\langl\ident{int}\rangl \}$,
$\sigma_2 = \ident{A}~\{ \ident{a}\!:\!\ident{int} \}$ and
$\sigma_3 = \ident{A}~\{ \ident{a}\!:\!\ident{int}, \ident{b}\!:\!\ident{int} \}$,
it is the case that $\sigma_1 \sqsubseteq \sigma_2$ and $\sigma_1 \sqsupseteq \sigma_2$ but
$\sigma_3 \sqsubseteq \sigma_1$ and not vice versa. 

Similarly to labels on the labelled top type (\S\ref{sec:inference-vars}), the nullable fields 
of records serve as annotations that provide access to additional values that may or may not be 
available in the input. In the provided code, these always have to be protected by a runtime check.

\begin{theorem}[Preferred shape function]
\label{thm:func}
For all $\sigma_1$ and $\sigma_2$ there exists exactly one $\sigma$ such that 
$\sigma_1 \tsep \sigma_2 \vdash \sigma$. 
\end{theorem}
\begin{proof}
The pre-conditions of rules in Figure~\ref{fig:subtyping-cst} are disjoint, with the exception 
of (\emph{sym}) and (\emph{refl}), but applying those does not affect the result. Reflexivity is
preserved recursively and all rules, symmetry does not enable different derrivations, even for
non-symmetric (\emph{nullable}) and (\emph{prim}).
\end{proof}

\begin{theorem}[Least upper bound]
\label{thm:lub}
If $\sigma_1 \triangledown \sigma_2 \vdash \sigma$ then $\sigma$ is a least upper bound, i.e. 
$\sigma \sqsupseteq \sigma_1$ and $\sigma \sqsupseteq \sigma_2$ and for all $\sigma'$ such that $\sigma' \sqsupseteq \sigma_1$
and $\sigma' \sqsupseteq \sigma_2$, it holds that $\sigma' \sqsupseteq \sigma$.
\end{theorem}
\begin{proof}
By induction over $\vdash$. The algorithm only infers the top shape \kvd{any} when for non-nullable
shapes of distinct tags and so no better preferred shape exists.
\end{proof}

\noindent
Next, we extend the core model (sufficient for the relativized safety) 
with \emph{labelled top types} discussed earleir.

% --------------------------------------------------------------------------------------------------

\begin{figure*}
  \noindent
  \begin{equation*}
  \textnormal{\footnotesize{(top-1)}}\;\;
  \inference
    {\exists i . \tytagof(\sigma_i) = \tytagof(\dropopt{\sigma}) & \sigma \tsep \sigma_i \vdash \sigma_i' & \tytagof(\sigma)\neq\ident{any}}
    {\sigma \tsep \kvd{any}\langl\sigma_1, \ldots, \sigma_n\rangl \vdash 
      \kvd{any}\langl\sigma_1, \ldots, \dropopt{\sigma_i'}, \ldots, \sigma_n\rangl}
  \;\;
  \inference
    {\nexists i . \tytagof(\sigma_i) = \tytagof(\dropopt{\sigma}) & \tytagof(\sigma)\neq\ident{any}}
    {\sigma \tsep \kvd{any}\langl\sigma_1, \ldots, \sigma_n\rangl \vdash 
      \kvd{any}\langl\sigma_1, \ldots, \sigma_n, \dropopt{\sigma}\rangl}
  \end{equation*}
  \vspace{-2em}

  % two union types
  \begin{equation*}
  \begin{array}{l}
  \inference[(top-2)\;]
    { (\tytagof(\sigma_i) = \tytagof(\sigma'_j)) \Leftrightarrow (i = j) \wedge (i \leq k)\\
        \forall i\in\{ 1 .. k \}.(\sigma_i \tsep \sigma'_i \vdash \sigma''_i) }
    { \begin{array}{l}
      \kvd{any}\langl \sigma_1, \ldots, \sigma_k,  \ldots, \sigma_n\rangl \tsep 
      \kvd{any}\langl \sigma'_1, \ldots, \sigma'_k, \ldots, \sigma'_m\rangl \vdash\\
      \kvd{any}\langl \sigma''_1, \ldots, \sigma''_k, \sigma_{k+1}, \ldots, \sigma_{n}, \sigma'_{k+1}, \ldots, \sigma'_{m}\rangl
      \end{array} }
  \end{array}    
  \begin{array}{l}
  \inference[(top-3)\;]
    {(\forall i\in\{1,2\}) & \tytagof(\sigma_1) \neq \tytagof(\sigma_2) \\ 
     \tytagof(\sigma_i) \neq \ident{any} & \nexists\sigma_i' . (\sigma_i = \kvd{option}\langl\sigma_i'\rangl)  }
    {\sigma_1 \tsep \sigma_2 \vdash \kvd{any}\langle\dropopt{\sigma_1}, \dropopt{\sigma_2}\rangle}
  \end{array}  
  \end{equation*}
  \caption{Extending the common preferred shape relation for labelled top shapes}
  \label{fig:subtyping-cst-var}
\end{figure*}

% --------------------------------------------------------------------------------------------------

\subsection{Adding labelled top type}
\label{sec:inference-vars}

When analyzing the structure of shapes, it suffices to consider a single top shape \kvd{any}.
However, the type providers need more information to provide typed access to the possible 
alternative shapes of data, such as XML nodes. To support track the possible shapes, we label 
the \kvd{any} shape:
%
\begin{equation*}
\sigma = \ldots \lsep \kvd{any}\langl \sigma_1, \ldots, \sigma_n\rangl
\end{equation*}
%
The shapes $\sigma_1, \ldots, \sigma_n$ represent statically known shapes that appear in the
sample and that we expose in the provided type. As discussed earlier (\S\ref{sec:providers-xml})
this is important when reading external \emph{open world} data. The labels do not affect the 
preferred shape relation and $\kvd{any}\langl \sigma_1, \ldots, \sigma_n\rangl$ should still be
seen as the top type, regardless of the labels.

The common preferred shape relation is extended to find a labelled top shape that best represents 
the sample. We limit the number of labels and avoid nesting by grouping shapes by the shape tag 
introduced earlier (Figure~\ref{fig:subtyping-cst}).
For example, rather than inferring $\kvd{any}\langl\ident{int}, \kvd{any}\langl\ident{bool}, \ident{float}\rangl\rangl$, 
our algorithm finds the common preferred shape of $\ident{int}$ and $\ident{float}$ and produces 
$\kvd{any}\langl\ident{float},\ident{bool}\rangl$. 

The three rules in Figure~\ref{fig:subtyping-cst-var} replace the earlier (\emph{top}). When 
combining a top with another shape (\emph{top-1}), the labelled top shape may or may not already 
contain a case with the tag of the other shape. If it does, the two shapes are combined, otherwise 
a new case is added. When combining two top types (\emph{top-2}), we group the labels that have 
shared tags. Finally, (\emph{top-3}) covers the case when we are combining two distinct non-top 
shapes. As top shapes implicitly permit \kvd{null} values, we use an auxiliary function $\dropopt{-}$ 
to make nullable shapes non-nullable (when possible) to simplify the label.

\paragraph{Properties.}
The revised algorithm stil finds a shape which is the least upper bound. This means that 
labelled top shape is only inferred when there is no other alternative.

Stating properties of the labels requires a finer relation than \emph{preferred shape}. In particular, 
it can only be done with respect to the \emph{sample}. We leave the details to future work, but we
note that the algorithm infers the best labels in the sense that there are labels that enable 
typed access to every possible value in the sample, but not more. The same is the case for nullable
fields of records.

\subsection{Inferring shapes from values}
\label{sec:formal-inferval}

The common preferred shape relation is at the core of the shape inference. What remains to be 
specified is how we obtain the shape from data. We represent JSON, XML and CSV documents using
the same first-order \emph{data} value (\S\ref{sec:impl-parsing}):
%
\begin{equation*}
\begin{array}{lcl}
 d &\narrow{=}& i \lsep f \lsep s \lsep \kvd{true} \lsep \kvd{false} \lsep \kvd{null} \\[0.1em]
   &\narrow{|}& [d_1; \ldots; d_n] \lsep \nu~\{ \nu_1 \mapsto d_1, \ldots, \nu_n \mapsto d_n \}
\end{array}
\end{equation*}
%
The first few cases represent primitive values ($i$ for integers, $f$ for floating
point numbers and $s$ for strings) and the \kvd{null} value. A collection is written as a 
list of values in square brackets. A record starts with a name $\nu$, followed by a 
sequence of field assignments $\nu_i \mapsto d_i$.

The following defines a mapping $\semalt{d_1,\ldots,d_n}$ which turns a collection of sample 
data $d_1, \ldots, d_n$ into a shape $\sigma$:
%
\begin{equation*}
\begin{array}{rclcrclcrcl}
 \semalt{i} &\narrow{=}& \ident{int} && \semalt{\kvd{null}}  &\narrow{=}& \kvd{null} && \semalt{\kvd{true}} &\narrow{=}& \ident{bool}\\
 \semalt{f} &\narrow{=}& \ident{float} && \semalt{s} &\narrow{=}& \ident{string} && \semalt{\kvd{false}}  &\narrow{=}& \ident{bool}\\
\end{array}
\end{equation*}
\noindent
\vspace{-0.5em}
\begin{equation*}
\begin{array}{l}
 \semalt{d_1, \ldots, d_n} = \sigma_n \quad\textnormal{where}\\[0.1em]
 \qquad\sigma_0 = \bot,~ \forall i\in \{ 1.. n \}.~ \sigma_{i-1} \triangledown \semalt{d_i} \vdash \sigma_i
 \\[0.5em]
 \semalt{[d_1; \ldots; d_n]} = [\semalt{d_1, \ldots, d_n}]
 \\[0.5em]
 \semalt{\nu~\{ \nu_1 \mapsto d_1, \ldots, \nu_n \mapsto d_n \}} =\\[0.1em]
 \qquad\nu~\{ \nu_1:\semalt{d_1}, \ldots, \nu_n :\semalt{d_n} \}
\end{array}
\end{equation*}
%
We overload the notation and write $\semalt{s}$ when inferring shape from a single value. Primitive 
values are mapped to their corresponding shapes. For records, we return infer field shapes
from the individual values. 

When infering a shape from multiple samples, we use the common preferred shape relation to find a 
common shape for all values (starting with $\bot$). This operation is used at the top-level 
(when calling a type provider with multiple samples) and also when inferring the shape of collection
elements.


% ==================================================================================================
% 
%    #######
%    #        ####  #####  #    #   ##   #      # ######   ##   ##### #  ####  #    #
%    #       #    # #    # ##  ##  #  #  #      #     #   #  #    #   # #    # ##   #
%    #####   #    # #    # # ## # #    # #      #    #   #    #   #   # #    # # #  #
%    #       #    # #####  #    # ###### #      #   #    ######   #   # #    # #  # #
%    #       #    # #   #  #    # #    # #      #  #     #    #   #   # #    # #   ##
%    #        ####  #    # #    # #    # ###### # ###### #    #   #   #  ####  #    #
%
% ==================================================================================================

\section{Formalising type providers}
\label{sec:formal}

In this section, we build the theoretical framework for proving relativised type safety of 
structural type providers. We discuss the runtime representation of documents and 
primitive operations (\S\ref{sec:formal-convert}), we embed these into a formal model of an F\# 
subset (\S\ref{sec:formal-ff}) and we describe how structural type providers turn
inferred structural types into F\# types (\S\ref{sec:formal-tp}).

% -------------------------------------------------------------------------------------------------

\begin{figure*}
\noindent
\begin{equation*}
\begin{array}{l}
\ident{asFloat}(i) \,\reduce f\quad(f = i)\\
\ident{asFloat}(d) \reduce f\quad(f = d)\\
\ident{asFloat}(f) \reduce f
\\[0.5em]
\ident{asDec}(i) \,\reduce d\quad(d = i)\\
\ident{asDec}(d) \reduce d
\end{array}
\qquad
\begin{array}{l}
\ident{hasType}(\nu \{ \nu_1 \!:\! \sigma_1, \ldots, \nu_n \!:\! \sigma_n \}, \nu'_? \{ \nu'_1\mapsto s_1, \ldots, \nu'_m\mapsto s_m \}) \reduce (\nu = \nu'_?) ~\wedge \\
  \quad (~ ((\nu_1 = \nu'_1) \wedge \ident{hasType}(\sigma_1, s_1)) \vee\ldots\vee ((\nu_1 = \nu'_m) \wedge \ident{hasType}(\sigma_1, s_m)) \vee \ldots \vee\\
  \quad ~\; ((\nu_n = \nu'_1) \wedge \ident{hasType}(\sigma_n, s_1)) \vee\ldots\vee ((\nu_n = \nu'_m) \wedge \ident{hasType}(\sigma_n, s_m))~)
\\[0.5em]
\ident{hasType}([\sigma], [s_1; \ldots; s_n]) \reduce \ident{hasType}(\sigma, s_1)\wedge\ldots\wedge\ident{hasType}(\sigma, s_n) \\
\ident{hasType}([\sigma], \kvd{null}) \reduce \kvd{true} \\  
\end{array}  
\end{equation*}
%
\vspace{-0.5em}
%
\begin{equation*}
\begin{array}{l}
\ident{isNull}(\kvd{null}) \reduce \kvd{true} \\
\ident{isNull}(\_) \reduce \kvd{false} 
\\[0.5em]
\ident{getField}(\nu,\nu_i, \nu~\{\ldots, \nu_i=s_i, \ldots\}) \reduce s_i\\
\ident{getField}(\bullet, \nu_i, \{\ldots, \nu_i=s_i, \ldots\}) \reduce s_i\\
\ident{getField}(\nu,\nu', \nu~\{\ldots, \nu_i=s_i, \ldots\}) \reduce \kvd{null}\quad(\nexists i.\nu_i=\nu' )\\
\ident{getField}(\bullet, \nu', \{\ldots, \nu_i=s_i, \ldots\}) \reduce \kvd{null}\quad(\nexists i.\nu_i=\nu' )
\\[0.5em]
\ident{getChildren}([s_1; \ldots; s_n]) \reduce [s_1; \ldots; s_n]  \\  
\ident{getChildren}(\kvd{null}) \reduce [~] 
\end{array}
~
\begin{array}{l}
\ident{hasType}(\ident{string}, t) \reduce \kvd{true} \\
\ident{hasType}(\ident{bool}, s) \reduce \kvd{true} \quad(\textnormal{when}~s\in{\kvd{true},\kvd{false}} )\\
\ident{hasType}(\ident{float}, s) \reduce \kvd{true} \quad(\textnormal{when}~s=i, s=d ~\textnormal{or}~ s=f) \\
\ident{hasType}(\ident{decimal}, s) \reduce \kvd{true} \quad(\textnormal{when}~s=i ~\textnormal{or}~ s=f) \\
\ident{hasType}(\ident{int}, i) \reduce \kvd{true}\\
\ident{hasType}(\kvd{option}\langl\sigma\rangl, s) \reduce \ident{hasType}(\sigma,s) \\
\ident{hasType}(\kvd{option}\langl\sigma\rangl, s) \reduce \kvd{true} \\
\ident{hasType}(\kvd{any}\langl\ldots\rangl, s) \reduce \kvd{true} \\
\ident{hasType}(\_, \_) \reduce \kvd{false} \\
\end{array}
\end{equation*}

\caption{Reduction rules for conversion functions}
\label{fig:op-conversions}
\vspace{-0.5em}
\end{figure*}

% -------------------------------------------------------------------------------------------------

\subsection{Structural values and conversions}
\label{sec:formal-convert}

As indicated by the subtyping, our system permits certain runtime conversions (e.g.~an integer
\num{1} can be treated as a floating-point \num{1.0}). The following primitive operations 
implement the conversions and other helpers:
%
\begin{equation*}
\begin{array}{lcl}
 op  &\narrow{=}& \ident{asDec}(s) \lsep \ident{asFloat}(s) \lsep \ident{getChildren}(s) \\
     &\narrow{|}& \ident{getField}(\nu?, \nu, s) \lsep \ident{isNull}(s) \lsep \ident{hasType}(\sigma, s)
\end{array}
\end{equation*}
%
The operations are used in code generated by type providers. Their behavior is defined
by the rules in Figure~\ref{fig:op-conversions}. The conversion functions (\ident{asDec}
and \ident{asFloat}) only perform conversions required by the subtyping (our actual 
implementation is more lax and performs additional conversions).

The \ident{getField} operation is used to access a field of a record. The operation ensures that
the actual record name matches the expected name (we write $\bullet$ for the name of an unnamed 
record). The \ident{getChildren} operation returns elements of a list and turns \kvd{null} into 
an empty collction.

Finally, we also define two helper functions. The \ident{isNull} operation is used to check whether 
value is \kvd{null} and \ident{hasType} is a runtime type test. The most complex case is handling 
of records where we check that for each field $\nu_1, \ldots, \nu_n$ in the type, the actual record 
value has a field of the same name with a matching type. The last line defines a ``catch all'' 
pattern, which returns \kvd{false} for all remaining cases. Although not elegant, the rules 
can be expressed using just Featherweight F\#, discussed in the next section.

% -------------------------------------------------------------------------------------------------

\begin{figure}
\noindent
\begin{equation*}
\begin{array}{rl}
 \textnormal{\footnotesize{(member)}}&
 \hspace{-0.4em}
 \inference
 { \kvd{type}~C(\overline{x:\tau})=\ldots \kvd{member}~N_i : \tau_i = e_i \ldots }
 { (\kvd{new}~C(\overline{v})).N_i \reduce e_i[\overline{x} \leftarrow \overline{v}] }\\
 \\
 \textnormal{\footnotesize{(eq1)}}&
 v=v\reduce\kvd{true} \qquad \textnormal{\footnotesize{(eq2)}}~~v=v'\reduce\kvd{false}\\
 \\
 \textnormal{\footnotesize{(cond1)}}&
 \hspace{-0.4em}
 \kvd{if}~\kvd{true}~\kvd{then}~e_1~\kvd{else}~e_2 ~\reduce~ e_1 \\
 \\
 \textnormal{\footnotesize{(cond2)}}&
 \hspace{-0.4em}
 \kvd{if}~\kvd{false}~\kvd{then}~e_1~\kvd{else}~e_2 ~\reduce~ e_2 \\
 \\
 \textnormal{\footnotesize{(match1)}}&
 \hspace{-1em}
 \begin{array}{l}
  \kvd{match}~\ident{None}~\kvd{with} \\
  \ident{Some}(x) \rightarrow e_1 \,|\, \ident{None} \rightarrow e_2
 \end{array} \hspace{-0.5em} ~\reduce~ e_2 \\
 \\
 \textnormal{\footnotesize{(match2)}}&
 \hspace{-1em}
 \begin{array}{l}
    \kvd{match}~\ident{Some}(v)~\kvd{with} \\
    \ident{Some}(x) \rightarrow e_1 \,|\, \ident{None} \rightarrow e_2
 \end{array} \hspace{-0.5em} ~\reduce~ e_1[x\leftarrow v]\\
 \\
 \textnormal{\footnotesize{(match3)}}&
 \hspace{-1em}
 \begin{array}{l}
  \kvd{match}~[v_1;\ldots;v_n]~\kvd{with} \\[0em]
  [x_1;\ldots;x_m ] \rightarrow e_1 \,|\, \_ \rightarrow e_2
 \end{array} \hspace{-0.5em} ~\reduce~ e_2\quad(m\neq n) \\
 \\
 \textnormal{\footnotesize{(match4)}}&
 \hspace{-1em}
 \begin{array}{l}
  \kvd{match}~[v_1;\ldots;v_n]~\kvd{with} \\[0em]
  [x_1;\ldots;x_n ] \rightarrow e_1 \,|\, \_ \rightarrow e_2
 \end{array} \hspace{-0.5em} ~\reduce~ e_1[\overline{x}\leftarrow\overline{v}] \\
 \\
 \textnormal{\footnotesize{(map)}}&
 \hspace{-0.4em}
 \ident{map}~(\lambda x.e)~[v_1; \ldots] ~\reduce~ [e[x\leftarrow v_1]; \ldots] \\
 \\
 \textnormal{\footnotesize{(ctx)}}&
 \hspace{-0.4em}
  E[e] \reduce E[e'] \qquad\qquad(\textnormal{when}~e \reduce e')\\
\end{array}
\end{equation*}

\caption{Featherweight F\# -- Remaining reduction rules}
\label{fig:ff-reduction}
\end{figure}

% -------------------------------------------------------------------------------------------------

\subsection{Featherweight F\#}
\label{sec:formal-ff}

We now extend the semantics discussed so far and add a minimal subset of F\# needed to model F\# 
Data. Type providers use classes and so we focus on the F\# object model and combine aspects of SML 
\cite{sml} and Featherweight Java \cite{fwjava}. 

We only need classes with parameter-less members and without inheritance. A class has a single 
implicit constructor and the declaration closes over constructor parameters. To avoid including all 
of ML, we only pick constructs for working with options and lists that we need later.
%
\begin{equation*}
\begin{array}{rcl}
 \tau &\narrow{=}& \ident{int} \lsep \ident{decimal} \lsep \ident{float} \lsep \ident{bool} \lsep \ident{string} \\[0.0em]
      &\narrow{|}& C \lsep \ident{StructVal} \lsep \ident{list}\langl\tau\rangl \lsep \ident{option}\langl\tau\rangl \\[0.6em]
 L &\narrow{=}& \kvd{type}~C(\overline{x:\tau}) = \overline{M} \\[0.0em]
 M &\narrow{=}& \kvd{member}~N:\tau=e \\[0.6em]
 v &\narrow{=}& s \lsep \ident{None} \lsep \ident{Some}(v) \lsep \kvd{new}~C(\overline{v}) \lsep [v_1; \ldots; v_n] \\[0.0em]
 e &\narrow{=}& s \lsep op \lsep e.N \lsep \kvd{new}~C(\overline{e}) \lsep {\kvd{if}~e_1~\kvd{then}~e_2~\kvd{else}~e_3}\\
   &\narrow{|}& \ident{None} \lsep\kvd{match}~e~\kvd{with}~\ident{Some}(x) \rightarrow e_1 \,|\, \ident{None} \rightarrow e_2 \\
   &\narrow{|}& \ident{Some}(e) \lsep [e_1;\ldots;e_n]\lsep \ident{map}~(\lambda x\rightarrow e_1)~e_2\\
   &\narrow{|}& e = e \lsep \kvd{match}~e~\kvd{with}~[x_1; \ldots; x_n] \rightarrow e_1 \,|\, \_ \rightarrow e_2
\end{array}
\end{equation*}

\noindent
The type \ident{StructVal} is a type of all structural values $s$. A class
definition $L$ consists of a constructor and zero or more members. Values $v$ include 
previously defined structural values $s$ and values for the option and list type; finally 
expressions $e$ include previously defined operations $op$, class construction, member access, 
conditionals and expressions for working with option values and lists. We include 
\ident{map} as a special construct to avoid making the language too complex.

\paragraph{Reduction.}
The reduction relation is of the form $e \reduce e'$. We also write 
$e \reduce^{*} e'$ to denote the reflexive and transitive closure of $\reduce$. The reduction rules
for operations $op$ were discussed earlier. Figure~\ref{fig:ff-reduction} shows the remaining
rules.

The (\emph{ctx}) rule performs a reduction inside a sub-expression specified by an evaluation context.
This models the eager evaluation of F\#. An evaluation context $E$ is defined as:
%
\begin{equation*}
\begin{array}{rcl}
 E &\narrow{=}& [\overline{v};E;\overline{e}] \lsep E.N \lsep \kvd{new}~C(\overline{v}, E, \overline{e})\\[0.1em]
   &\narrow{|}& \ident{map}~(\lambda x\rightarrow e)~E \lsep \kvd{if}~E~\kvd{then}~e_1~\kvd{else}~e_2 \\[0.1em]
   &\narrow{|}& \ident{Some}(E) \lsep op(E) \lsep E = e \lsep v = E \\[0.1em]
   &\narrow{|}& \kvd{match}~E~\kvd{with}~\ident{Some}(x) \rightarrow e_1 \,|\, \ident{None} \rightarrow e_2 \\[0.1em]
   &\narrow{|}& \kvd{match}~E~\kvd{with}~[x_1; \ldots; x_n] \rightarrow e_1 \,|\, \_ \rightarrow e_2
\end{array} 
\end{equation*}

\noindent
The evaluation first reduces arguments of functions and the evaluation proceeds from left to right 
as denoted by $\overline{v}, E, \overline{e}$ in constructor arguments or $\overline{v};E;\overline{e}$
in list initialization.

We write $e[\overline{x} \leftarrow \overline{v}]$ for the result of replacing variables $\overline{x}$ by
values $\overline{v}$ in an expression. The (\emph{member}) rule reduces a member access using a class 
definition in the assumption to obtain the body of a member. The remaining six rules
give standard reductions for conditionals and pattern matching.

We omit expressions $e \vee e$ and $e \wedge e$ that are used in Figure~\ref{fig:op-conversions}, 
as those can be easily defined as syntactic sugar using \kvd{if}. All expressions reduce to a value in a 
finite number of steps or get stuck due to an error condition. An error condition can be a wrong 
argument passed to conditional, pattern matching or one of the primitives from Figure~\ref{fig:op-conversions}.

% -------------------------------------------------------------------------------------------------

\begin{figure}
\noindent  
\begin{equation*}
\inference
  {L; \Gamma \vdash e_1 : \ident{StructVal}}
  {L; \Gamma \vdash [e_1; \ldots; e_n]:\ident{StructVal}}
\quad  
\inference
  {~}
  {L; \Gamma \vdash n : \ident{int}}
\end{equation*}
\begin{equation*}
\inference
  {L; \Gamma \vdash e_1 : \tau}
  {L; \Gamma \vdash [e_1; \ldots; e_n]:\ident{list}\langl\tau\rangl}
\quad
\inference
  {~}
  {L; \Gamma \vdash s : \ident{StructVal}}
\end{equation*}
\vspace{0.5em}
\begin{equation*}
\inference
  {L; \Gamma \vdash e : C \\ \kvd{type}~C(\overline{x:\tau}) = ..\;\kvd{member}~N_i : \tau_i = e_i\;.. \in L}
  {L; \Gamma \vdash e.N_i:\tau_i}
\end{equation*}
\vspace{0.25em}
\begin{equation*}
\inference
  {L; \Gamma \vdash e_i : \tau_i & \kvd{type}~C(x_1:\tau_1, \ldots, x_n:\tau_n) = \ldots \in L}
  {L; \Gamma \vdash \kvd{new}~C(e_1, \ldots, e_n):C}
\end{equation*}

\caption{Featherweight F\# -- Fragment of type checking}
\label{fig:ff-typecheck}
\end{figure}

% -------------------------------------------------------------------------------------------------

\paragraph{Type checking.} 
Typing rules in Figure~\ref{fig:ff-typecheck} are written using a judgement
$L; \Gamma \vdash e : \tau$ where the context also contains a set of class declarations $L$.
The fragment demonstrates the key differences from Standard ML and Featherweight Java:
%
\begin{itemize}
\item[--] All structural values $s$ have the type \ident{StructVal}, but some have other types
  (Booleans, strings, integers, etc.) as illustrated by the rule for $n$.
  For other values, \ident{StructVal} is the only type -- this includes records and \kvd{null}.
\item[--] A list containing other structural values $[s_1; \ldots; s_n]$ has a type \ident{StructVal},
  but can also have the $\ident{list}\langl\tau\rangl$ type. Conversely, lists that contain
  non-structural values like objects or options are not of type \ident{StructVal}.
\item[--] Operations $op$ (omitted) are treated as functions, accepting 
  \ident{StructVal} and producing an appropriate result type.
\item[--] Rules for checking class construction and member access are similar to corresponding
  rules of Featherweight Java.  
\end{itemize}
%
An important part of Featherweight Java that is omitted here is the checking of type declarations
(ensuring the members are well-typed). We consider only classes generated by our type providers 
and those are well-typed by construction.

% -------------------------------------------------------------------------------------------------

\begin{figure*}
\noindent
\begin{equation*}
\quad\qquad\boxed{
\begin{array}{rcl}
 \nameoftag(\ident{string}) &\narrow{=}& \ident{String} \\
 \nameoftag(\ident{bool}) &\narrow{=}& \ident{Boolean} \\
\end{array}
\qquad
\begin{array}{rcl}
 \nameoftag(\ident{number}) &\narrow{=}& \ident{Number} \\
 \nameoftag(\ident{collection}) &\narrow{=}& \ident{List} \\
\end{array}
\qquad
\begin{array}{rcl}
 \nameoftag(\ident{record}) &\narrow{=}& \ident{Record} \\
 \nameoftag(\ident{named}\;\nu) &\narrow{=}& \nu \\
\end{array}
}
\end{equation*}

\begin{multicols}{2}
% Primitive structural types become corresponding F# types and conversion is inserted
\noindent
\begin{equation*}
\begin{array}{l}
 \sem{\sigma_p}_e = \tau_p,op(e),\emptyset\quad\textnormal{where}~\tau_p = \sigma_p \\[0.2em]
\quad\sigma_p, op\in  \{~(\ident{decimal},\ident{asDec}), (\ident{float},\ident{asFloat})~\}
\end{array}
\end{equation*}
%
% Records become classes
\begin{equation*}
\begin{array}{l}
 \sem{\,\nu \{ \nu_1 : \sigma_1, \ldots, \nu_n : \sigma_n \}\,}_e = \\[0.1em]
 \quad C, \kvd{new}~C(e), L_1\cup\ldots\cup L_n\cup\{ L \}\quad\textnormal{where}\\[0.6em]
 \qquad \;\;C~\textnormal{is a fresh class name} \\[0.1em]
 \qquad \;\,\,L = \kvd{type}~C(v:\ident{StructVal})~=~M_1\ldots M_n  \\[0.1em]
 \qquad M_i = \kvd{member}~\nu_i:\tau_i=e_i\\[0.1em]
 \qquad \tau_i, e_i, L_i = \sem{\sigma_i}_{e'},\;\; e'=\ident{getField}(\nu, \nu_i, e)\\[0.6em]
\end{array}
\end{equation*}
%
% Collections
\begin{equation*}
\begin{array}{l}
 \sem{\,[\sigma]\,}_e = \ident{list}\langl\tau\rangl, e_b, L \;\;\textnormal{where}\\[0.4em]
 \qquad e_b = \ident{map}~(\lambda x\rightarrow e')~(\ident{getChildren}(e)) \\[0.1em]
 \qquad \tau, e', L = \sem{\hat{\sigma}}_x
\end{array}
\end{equation*}
%
% Anything else
\begin{equation*}
\begin{array}{l}
 \sem{\bot}_e = \sem{\kvd{null}}_e = \ident{StructVal}, e, \emptyset
\end{array}
\end{equation*}

\noindent
\begin{equation*}
\hspace{-2.5em}
\begin{array}{l}
 \sem{\sigma_p}_e = \tau_p,e,\emptyset\quad\textnormal{where}~\tau_p = \sigma_p \\[0.2em]
\quad\sigma_p \in  \{~ \ident{string},\ident{bool},\ident{int}~\}\\[0.6em]
\end{array}
\end{equation*}
%
% Sum type
\begin{equation*}
\hspace{-2.5em}
\begin{array}{l}
 \sem{\,\kvd{any}\langl\sigma_1, \ldots, \sigma_n\rangl\,}_e = \\[0.1em]
 \quad C, \kvd{new}~C(e), L_1\cup\ldots\cup L_n\cup\{ L \}\;\;\textnormal{where}\\[0.6em]
 \qquad \;\;C~\textnormal{is a fresh class name} \\[0.1em]
 \qquad \;\,\,L = \kvd{type}~C(v:\ident{StructVal})~=~M_1\ldots M_n \\[0.1em]
 \qquad M_i = \kvd{member}~\nu_i:\ident{option}\langl\tau_i\rangl=\\[0.1em]
 \hspace{5.8em}  \kvd{if}~\ident{hasType}(\sigma_i, v)~\kvd{then}~
     \ident{Some}(e_i)~\kvd{else}~\ident{None} \\[0.1em]
 \qquad \tau_i, e_i, L_i = \sem{\sigma_i}_e,\;\; t_i = \tytagof{(\sigma_i)},\;\; \nu_i=\nameoftag{(t_i)}
\end{array}
\end{equation*}
%
% Option values
\begin{equation*}
\hspace{-2.5em}
\begin{array}{l}
 \sem{\hat{\sigma}\;\,\kvd{option}}_e = \\[0.2em]
 \hspace{1.25em} \ident{option}\langl\tau\rangl, \kvd{if}~\ident{isNull}~e~\kvd{then}~\ident{None}~\kvd{else}~\ident{Some}(e'), L\\[0.2em] 
 \hspace{1.25em} \textnormal{where}~\tau, e', L = \sem{\hat{\sigma}}_e
\end{array}
\end{equation*}
\end{multicols}

\caption{Type provider -- generation of featherweight F\# types from inferred structural types}
\label{fig:tp-generation}
\vspace{-0.5em}
\end{figure*}

% -------------------------------------------------------------------------------------------------

\subsection{Type providers}
\label{sec:formal-tp}

So far, we defined the type inference algorithm which produces a structural type $\sigma$ from one 
or more sample documents (\S\ref{sec:inference}) and we defined a simplified model of evaluation
of F\# (\S\ref{sec:formal-ff}) and F\# Data runtime (\S\ref{sec:formal-tp}). In this section, we 
define how the type providers work, linking the two parts.

All F\# Data type providers take (one or more) sample documents, infer a common supertype $\sigma$
and then use it to generate F\# types that are exposed to the programmer.\footnote{The actual 
implementation provides \emph{erased types} as described in \cite{fsharp-typeprov}. Here, we treat 
the code as actually generated. This is an acceptable simplification, because F\# Data type providers 
do not rely on laziness that is available through erased types.}

\paragraph{Type provider mapping.}
A type provider produces an F\# type $\tau$ together with an expression that wraps an input
value (of type \ident{StructVal}) as a value of type $\tau$ and a collection of class definitions. 
We express it using the following mapping:
%
\begin{equation*}
\sem{-}_{-} : (\sigma\times e) \rightarrow (\tau \times e' \times L)
\end{equation*}
%
The mapping $\sem{\sigma}_e$ takes an inferred structural type $\sigma$ and an expression $e$, 
which represents code to obtain a structural value that is being wrapped. It returns an F\# type 
$\tau$, an expression $e'$ which constructs a value of type $\tau$ using $e$ and also a set of 
generated class definitions $L$.

Figure~\ref{fig:tp-generation} shows the rules that define $\sem{-}_{-}$. Primitive types are all
handled by two rules -- for \ident{decimal} and \ident{float}, we insert a call to an appropriate 
conversion function from Figure~\ref{fig:op-conversions}.

For records, we generate a class $C$ that takes a structural value as constructor
parameter. For each record field, we generate a member with the same name as the field.\footnote{The actual
F\# Data implementation also capitalizes the names.} The body of the member calls \ident{getField} and then
wraps this expression using $\sem{\sigma_i}$ which maps the field (structural value of type $\sigma_i$) into 
an F\# value of type $\tau_i$. The returned expression creates a new instance of $C$ and the mapping returns 
the class $C$ together with all recursively generated classes. Note that the class
name $C$ is not directly accessed by the user and so we can use arbitrary name, although the actual 
implementation in F\# Data attempts to infer a reasonable name.\footnote{For example, in 
\ident{\{\str{person}:\{\str{name}:\str{Tomas}\}\}}, the nested record will be named \ident{Person}
based on the name of the parent record field.}

A collection type becomes an F\# $\ident{list}\langl\tau\rangl$. The returned expression calls \ident{getChildren}
(which turns \kvd{null} into an empty list) and then uses \ident{map} to convert nested values to 
values of an F\# type $\tau$. The handling of option type is similar; if the value is not \kvd{null},
we wrap the recursively generated conversion expression $e'$ in the \ident{Some} constructor.

As discussed earlier, variant types are also generated as F\# classes with properties. Given a variant
$\kvd{any}\langl\sigma_1, \ldots, \sigma_n\rangl$, we get corresponding F\# types $\tau_i$ and generate 
$n$ members of type $\ident{option}\langl \tau_i\rangl$. When the member is accessed, we need to perform
a runtime type test using \ident{hasType} to ensure that the value has the right type (similarly to runtime 
type conversions from the top type in languages like Java). If the type matches, a \ident{Some} value is 
returned. The type inference algorithm also guarantees that there is only one case for each type tag 
(\S\ref{sec:inference-commonsuper}) and so we can use the tag when naming the generated member 
(using the \ident{nameof} function).

\paragraph{Example 1.}
To illustrate how the mechanism works, we consider two examples. First, assume 
that the inferred type is a record  
$\{~\ident{Age}\!:\!\kvd{option}\langl\ident{int}\rangl, \ident{Name}\!:\!\ident{string}~ \}$. 
The rules from Figure~\ref{fig:tp-generation} produce the following class:
%
\begin{equation*}
\begin{array}{l}
 \kvd{type}~\ident{Person}(\ident{v}:\ident{StructVal})~= \\[0.1em]
 \quad \kvd{member}~\ident{Age}~:~\ident{option}\langl\ident{int}\rangl~= \\[0.1em]
 \qquad \kvd{if}~\ident{isNull}~(\ident{getField}(\ident{Person},\ident{Age}, \ident{v}))~\kvd{then}~\ident{None} \\[0.1em]
 \qquad \kvd{else}~\ident{Some}(\ident{asInt}(\ident{getField}(\ident{Person},\ident{Age}, \ident{v}))) \\[0.1em]
 \quad \kvd{member}~\ident{Name}~:~\ident{string}~= \\[0.1em]
 \qquad \ident{asStr}(\ident{getField}(\ident{Person},\ident{Name}, \ident{v}))
\end{array}
\end{equation*}
%
The body of the \ident{Age} member is produced by the case for optional types applied to an expression
$\ident{getField}(\ident{Person},\ident{Age},v)$. If the returned field is not \kvd{null}, then the member
calls \ident{asInt} and wraps the result in \ident{Some}. Note that \ident{getField} is defined even 
when the field does not exist, but it returns \kvd{null}. This lets us treat missing fields as 
optional. An F\# type corresponding to the (structural) record is \ident{Person} and a structural 
value $s$ is wrapped by by calling $\kvd{new}~\ident{Person}(s)$.

\paragraph{Example 2.} The second example illustrates the remaining types including collections and 
variants. Reusing \ident{Person} from the previous example, consider 
$[\kvd{any}\langl\ident{Person},\ident{string}\rangl]$, a collection which contains a mix 
of \ident{Person} and string values:
%
\begin{equation*}
\begin{array}{l}
 \kvd{type}~\ident{PersonOrString}(v:\ident{StructVal})~= \\[0.1em]
 \quad \kvd{member}~\ident{Person}~:~\ident{option}\langl\ident{Person}\rangl~= \\[0.1em]
 \qquad \kvd{if}~\ident{hasType}(\{\ident{Age}\!:\!\kvd{option}\langl\ident{int}\rangl, \ident{Name}\!:\!\ident{string}\}, v)~\\[0.1em]
 \qquad\quad \kvd{then}~\ident{Some}(\kvd{new}~\ident{Person}(v))~\kvd{else}~\ident{None} \\[0.1em]
 \quad \kvd{member}~\ident{String}~:~\ident{option}\langl\ident{string}\rangl~= \\[0.1em]
 \qquad \kvd{if}~\ident{hasType}(\ident{string}, v)~\\[0.1em]
 \qquad\quad \kvd{then}~\ident{Some}(\ident{asStr}(v))~\kvd{else}~\ident{None}
\end{array}
\end{equation*}
%
The type provider maps the structural type to an F\# type $\ident{list}\langl\ident{PersonOrString}\rangl$. 
Given a structural document value $s$, the code to obtain the wrapped F\# value is:
%
\begin{equation*}
\ident{map}~(\lambda x\rightarrow\kvd{new}~\ident{PersonOrString}(x))~(\ident{getChildren}(s))
\end{equation*}

The \ident{PersonOrString} type contains one member for each of the variant case. In the body, they
check that the value has the correct type using \ident{hasType}. This also implicitly handles \kvd{null}
by returning \kvd{false}. As discussed earlier, variants provide easy access to the known cases
(\ident{string} or \ident{Person}), but they are robust with respect to unexpected inputs.



% ==================================================================================================
%
%    #######
%       #    #   # #####  ######     ####    ##   ###### ###### ##### #   #
%       #     # #  #    # #         #       #  #  #      #        #    # #
%       #      #   #    # #####      ####  #    # #####  #####    #     #
%       #      #   #####  #              # ###### #      #        #     #
%       #      #   #      #         #    # #    # #      #        #     #
%       #      #   #      ######     ####  #    # #      ######   #     #
%
% ==================================================================================================

\section{Relativized type safety}
\label{sec:safety}

Informally, the safety property for structural type providers states that, given representative sample
documents, any code that can be written using the provided types is guaranteed to work. We call this 
\emph{relativized safety}, because we cannot avoid \emph{all} errors. In particular, one can always
provide an input that has a different structure than any of the samples. In this case, it is expected 
that the code will throw an exception in the implementation (or get stuck in our model).

More formally, given a set of sample documents, code using the provided type is guaranteed to work if 
the inferred type of the input is a subtype of any of the samples. Going back to 
\S\ref{sec:inference-subtyping}, this means that:
%
\begin{itemize}[noitemsep]
\item[--] Input can contain smaller numerical values (e.g., if a sample contains float, the input can contain an integer)
\item[--] Records in the input can have additional fields
\item[--] Records in the input can have fewer fields, provided that the type of the field is missing in some of the samples
\item[--] When a variant is inferred from the sample, the actual input can also contain any other value  
\end{itemize}
%
The following lemma states that the provided code (generated in Figure~\ref{fig:tp-generation})
works correctly on an input $s'$ that is a subtype of the sample $s$. More formally, the provided
provided expression (with input $s'$) can be reduced to a value and, if it is a class,
all its members can also be reduced to values.

\begin{lemma}[Correctness of provided types]
\label{thm:tp-correctness}
Given a sample value $s$ and an input value $s'$ such that $\semalt{s} \sqsupseteq \semalt{s'}$
and provided type, expression and class declarations $\tau, e, L = \sem{\semalt{s}}_{s'}$, 
then $e \reduce^{*} v$ and if $\tau$ is a class ($\tau=C$) then for all members $N_i$ of the 
class $C$, it holds that $e.N_i \reduce^{*} v$.
\end{lemma}
\begin{proof}
By induction over the structure of $\sem{-}_-$. For primitives, the conversion functions accept all subtypes.
For other cases, analyze the provided code to see that it can work on all subtypes (\emph{e.g.}~\ident{getChildren}
works on \kvd{null} values, \ident{getField} returns \kvd{null} when a field is missing and, for variants,
the value has the correct type as guaranteed by \ident{hasType}.
\end{proof}

\noindent
This shows that the provided types are correct with respect to subtyping. Our key
theorem states that, for any input (which is a subtype of any of the samples) and 
any expression $e$, a well-typed program that uses the provided types does not ``go wrong''.
Using standard syntactic type safety  \cite{syntactic}, we prove type preservation 
(reduction does not change type) and progress (an expression that is not a value can be reduced).

\begin{theorem}[Relativized safety]
\label{thm:safety}
Assume $s_1, \ldots, s_n$ are samples, $\sigma=\semalt{s_1, \ldots, s_n}$ is an inferred
type and $\tau,e,L = \sem{\sigma}_x$ are a type, expression and class definitions generated by a 
type provider.

For all new inputs $s'$ such that $\exists i.(\semalt{s_i} \sqsupseteq \semalt{s'})$, let $e_s=e[x\leftarrow s']$
be an expression (of type $\tau$) that wraps the input in a provided type. Then, for any expression $e_c$
(user code) such that $\emptyset; y:\tau \vdash e_c:\tau'$ and $e_c$ does not contain primitive operations
$op$ as a sub-expression, it is the case that $e_c[y\leftarrow e_s] \reduce^{*} v$ for some value $v$ and
also $\emptyset; \vdash v : \tau$.
\end{theorem}
\begin{proof}
We discuss the two parts of the proof separately as type preservation (Lemma~\ref{thm:rs-preservation})
and progress (Lemma~\ref{thm:rs-progress}).
\end{proof}

\begin{lemma}[Preservation]
\label{thm:rs-preservation}
Given the class definitions $L$ generated by a type provider as specified in
the assumptions of Theorem~\ref{thm:safety}, then if $\Gamma \vdash e : \tau$ and 
$e \reduce^{*} e'$ then $\Gamma \vdash e' : \tau$.
\end{lemma}
\begin{proof}
By induction over the reduction $\reduce$. The cases for the ML subset of Featherweight F\# 
are standard. For (\emph{member}), we check that code generated by type providers
in Figure~\ref{fig:tp-generation} is well-typed.
\end{proof}

\noindent
The progress lemma states that evaluation of a well-typed program does not reach an undefined state. 
This is not a problem for the (standard) ML subset and object-oriented subset of the calculus. The 
problematic part are the primitive functions (Figure~\ref{fig:op-conversions}). Given a structural 
value (of type \ident{StructVal}), the reduction can get stuck if the value does not have a structure 
required by a specific primitive.

The Lemma~\ref{thm:tp-correctness} guarantees that this does not happen inside the provided type.
In Theorem~\ref{thm:safety}, we carefully state that we only consider expressions $e_c$ which 
``[do] not contain primitive operations $op$ as sub-expressions''. This makes sure that the only 
code working with structural values is the code generated by the type provider.

\begin{lemma}[Progress]
\label{thm:rs-progress}
Given the assumptions and definitions from Theorem~\ref{thm:safety}, it is the case that
$e_c[y\leftarrow e_s] \reduce e_c'$.
\end{lemma}
\begin{proof}
Proceed by induction over the typing derivation of $L; \emptyset \vdash e_c[y\leftarrow e_s] : \tau'$. 
The cases for the ML subset are standard. For member access, we rely on Lemma~\ref{thm:tp-correctness}.
\end{proof}



% ==================================================================================================
%
%   ###                                                                                     
%    #  #    # #####  #      ###### #    # ###### #    # #####   ##   ##### #  ####  #    # 
%    #  ##  ## #    # #      #      ##  ## #      ##   #   #    #  #    #   # #    # ##   # 
%    #  # ## # #    # #      #####  # ## # #####  # #  #   #   #    #   #   # #    # # #  # 
%    #  #    # #####  #      #      #    # #      #  # #   #   ######   #   # #    # #  # # 
%    #  #    # #      #      #      #    # #      #   ##   #   #    #   #   # #    # #   ## 
%   ### #    # #      ###### ###### #    # ###### #    #   #   #    #   #   #  ####  #    # 
%
% ==================================================================================================

\section{Practical experience}
\label{sec:impl}

The F\# Data library has been widely adopted by the industry and is one of the most downloaded
F\# libraries.\footnote{At the time of writing, the library has over 80,000 downloads on NuGet 
(package repository), 1,821 commits and 44 contributors on GitHub.} A practical demonstration of 
development using the library can be seen in an attached screencast and additional documentation can be
found at \url{http://fsharp.github.io/FSharp.Data}.

In this section, we discuss our practical experience with the safety guarantees provided by the
F\# Data type providers and other notable aspects of the implementation.


\subsection{Relativized safety in practice}
\label{sec:safety-discuss}

The \emph{relativized safety} property does not guarantee the same amount of safety as traditional
ML type safety, but it reflects the reality of programming with external data sources that is 
increasingly important \cite{age-of-web}. Type providers do not reduce the safety -- they simply 
illuminate the existing issues.

One such issue is the handling of schema change. With type providers, the sample is captured 
at compile-time. If the schema changes later (so that the input is no longer a subtype of the 
sample), the program fails at runtime and developers have to handle the exception. This is the 
same problem that happens when reading data using any other library.

F\# Data can help discover such errors earlier. Our first example (\S\ref{sec:introduction})
points the JSON type provider at a sample using a live URL. This has the advantage that a re-compilation 
fails when the schema changes, which is an indication that the program needs to be updated to reflect the
change.

In general, there is no better solution for plain XML, CSV and JSON data sources. However, some data 
sources provide versioning support (with meta-data about how the schema changed). For those, a type 
provider could adapt automatically, but we leave this for future work.

% -------------------------------------------------------------------------------------------------

\subsection{Parsing structured data}
\label{sec:impl-parsing}

In our formalization, we treat XML, JSON and CSV uniformly as \emph{structural values}. With the addition of 
named records (for XML nodes), the definition of structural values is rich enough to capture all 
three formats\footnote{The same mechanism has later been used by the HTML type provider 
(\url{http://fsharp.github.io/FSharp.Data/HtmlProvider.html}), which provides similarly easy 
access to data in HTML tables and lists.}. However, parsing real-world data poses a number of practical issues.

\paragraph{Reading CSV data.}
When reading CSV data, we read each row as an unnamed record and return a collection of rows.
One difference between JSON and CSV is that in CSV, the literals have no data types and so 
we also need to infer the type of primitive values. For example:
%
{\small{
\begin{verbatim}
  Ozone, Temp, Date,       Autofilled
  41,    67,   2012-05-01, 0
  36.3,  72,   2012-05-02, 1
  12.1,  74,   3 kveten,   0
  17.5,  #N/A, 2012-05-04, 0
\end{verbatim}
}}
%
\noindent
The value {\small\ttfamily \#N/A} is commonly used to represent missing values in CSV and is treated
as \kvd{null}. The \ident{Date} column uses mixed formats and is inferred as \ident{string} 
(we support many date formats and ``May 3'' would be parsed correctly). More interestingly,
we also infer \ident{Autofiled} as Boolean, because the sample contains only $0$ and $1$.
This is handled by adding a \ident{bit} type which is a subtype of both \ident{int} and \ident{bool}.

\paragraph{Reading XML documents.}
Mapping XML documents to structural values is perhaps the most interesting. For each node, we
create a named record. Attributes become record fields and the body becomes a field with a special
name:
%
{\small{
\begin{verbatim}
  <root id="1">
    <item>Hello!</item>
  </root>    
\end{verbatim}
}}
%
\noindent
This XML becomes a record \ident{root} with fields \ident{id} and $\bullet$ for the body. 
The nested element contains only the $\bullet$ field with the inner text. As with CSV, we
infer type of primitive values:
%
\begin{equation*}
\ident{root}~\{ \ident{id} \mapsto 1, \bullet \mapsto [ \ident{item}~\{ \bullet \mapsto \str{Hello!} \}] \}
\end{equation*}
%
When generating types for XML documents, we also lifts the members nested under the $\bullet$ 
field into the parent type to simplify the structure of the generated type.

The XML type provider also includes an option to use \emph{global inference}. In that case, 
the inference from values (\ref{sec:formal-inferval}) unifies the types of all records with the 
same name. This is useful because, for example, in XHTML all {\small\ttfamily <table>} elements
will be treated as values of the same type.

% -------------------------------------------------------------------------------------------------

\subsection{Heterogeneous collections} 
\label{sec:impl-hetero}

When introducing type providers (\S\ref{sec:providers-sum}), we mentioned that F\# Data 
implements a special handling of heterogeneous collections. This allows us to avoid inferring a 
variant types in many common scenarios. In the earlier example, a sample collection 
contains a record (with \strf{pages} and \strf{page} fields) and a nested collection with values.

Rather than storing a single type for the collection elements as in $[\sigma]$, heterogeneous
collections store multiple possible element types together with their \emph{  inferred multiplicity} 
(zero or one, exactly one, zero or more):
%
\begin{equation*}
\begin{array}{rcl}
 \psi &\narrow{=}& 1? \lsep 1 \lsep \ast \\
 \sigma &\narrow{=}& ~\ldots \lsep [\sigma_1, \psi_1 | \ldots | \sigma_n, \psi_n ]
\end{array}
\end{equation*}
%
We omit the details, but finding a common supertype of two heterogeneous 
collections is analogous to the handling of variants. We merge cases with the same tag (by finding 
their common super-type) and calculate their new shared multiplicity (for example, by turning 
$1$ and $1?$ into $1?$).



% ==================================================================================================
%
%    ######
%    #     # ###### #        ##   ##### ###### #####     #    #  ####  #####  #    #
%    #     # #      #       #  #    #   #      #    #    #    # #    # #    # #   #
%    ######  #####  #      #    #   #   #####  #    #    #    # #    # #    # ####
%    #   #   #      #      ######   #   #      #    #    # ## # #    # #####  #  #
%    #    #  #      #      #    #   #   #      #    #    ##  ## #    # #   #  #   #
%    #     # ###### ###### #    #   #   ###### #####     #    #  ####  #    # #    #
%
% ==================================================================================================

\section{Related and future work}
\label{sec:related}

We connect two lines of research: integration of external data into statically-typed 
programming languages and inferring types for real-world data sources. We build on F\# type 
providers \cite{fsharp-typeprov,fsharp-typeprov-ddfp,idris-tp,liteq}, but our paper is novel 
in that it discusses the theory and safety of a concrete type provider. 

\paragraph{Extending the type systems.} 
Previous work that integrates external data, such as XML \cite{xduce,xduce-ml} and databases 
\cite{links,linq}, into a programming language, required the user to define the schema
or it has an ad-hoc extension that reads the schema.

C$\omega$ \cite{comega-xs} is the most similar to F\# Data. It extends C\# with types similar to our
structural types (including similar heterogeneous collections), but it does not infer the types
from a sample and extends the type system of the host language (rather than using general purpose
embedding).

\paragraph{Advanced type systems.}
A number of other advanced type system features could be used to tackle the problem discussed 
in this paper. The Ur \cite{ur} language has a rich system for working with records; 
meta-programming \cite{template-hask}, \cite{th-camlp4} and multi-stage programming \cite{multi-stage}
could be used to generate code for the provided types; and gradual typing \cite{gradual,gradual-js} 
can add typing to existing dynamic languages. As far as we are aware, none of these 
systems have been used to provide the same level of integration with XML, CSV and JSON.

\paragraph{Typing real-world data.}
Recent work \cite{typing-json} infers a succinct type of large JSON datasets using MapReduce.
It fuses similar types based on similarity. This is more sophisticated than our technique, but it 
makes formal specification of safety (Theorem~\ref{thm:safety}) difficult. Extending our 
\emph{relativized safety} to \emph{probabilistic safety} is an interesting future work.

The PADS project \cite{pads-dsl,pads-ml} tackles a more general problem of handling \emph{any} data format.
The schema definitions in PADS are similar to our structural type. The structure inference for LearnPADS
\cite{pads-learn} infers the data format from a flat input stream. A PADS type provider could follow
many of the patterns we explore in this paper, but formally specifying the safety property would be
challenging.

\section{Conclusions}
\label{sec:conclusions}

We explored the F\# Data type providers for XML, CSV and JSON. As most real-world data do not come 
with an explicit schema, the library uses \emph{type inference} that deduces a type from a set of 
samples. Our type inference algorithm is based on a common supertype relation. For usability 
reasons, it prefers records and avoids variant types. The algorithm is predictable, which is 
important as developers need to understand how changing the samples affects the resulting types.

We explore the programming language theory behind type providers. F\# Data is a prime example of 
type providers, but our work also demonstrates a more general point. The types generated by type 
providers can depend on external input and so we can only guarantee \emph{relativized safety}, 
which says that a program is safe only if the actual inputs satisfy additional conditions --
in our case, they have to be subtypes of one of the samples.

Type providers have been described before, but this paper is novel in that it explores concrete 
type providers from the perspective of programming language theory. This is particularly important
for F\# Data type providers, which have been widely adopted by the industry.

% \acks
% We would like to thank to the F\# Data contributors on GitHub and other colleagues working on type providers,
% including Jomo Fisher, Keith Battocchi and Kenji Takeda.

\bibliographystyle{abbrvnat}
\bibliography{paper}

\end{document}